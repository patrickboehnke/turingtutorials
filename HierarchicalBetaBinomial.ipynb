{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6dbe9e8",
   "metadata": {},
   "source": [
    "Let's start off by loading the packages we are going to need for this tutorial. This step will take a while because Julia has to compile each package.\n",
    "\n",
    "If you don't have these packages installed you can install them by first:\n",
    "import Pkg\n",
    "Pkg.add(\"Turing\")\n",
    "Pkg.add(\"StatsPlots\")\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add(\"DataFrames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399c3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, StatsPlots;\n",
    "using Turing;\n",
    "using DataFrames;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ac4ead",
   "metadata": {},
   "source": [
    "Now we want to define a quick helper function to help us extract parameters from the MCMC chains that we'll run later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ababbe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extract (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function extract(chain, sym; burn=0, is_scalar=true)\n",
    "    if is_scalar\n",
    "        tail = chain[sym].data[(burn + 1):end, 1]\n",
    "    else\n",
    "        tail = group(chain, sym).value.data[(burn + 1):end, :, 1]\n",
    "    end\n",
    "    return tail\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715982b1",
   "metadata": {},
   "source": [
    "In our model we had an experiment that was repeated a few times and for each experiment we have know how many successful trials (y[i]) there were and how many total trials (n[i]). In order to compute this model we're going to need to loop over all the observations so first we get the length and store it in nobs.\n",
    "\n",
    "Then we apply the priors for our parametrization which we draw from a Normal distribution with a mean of 0 and standard deviation of 1. Since Œ±z represents the parameters for each experiment we need to apply a 'trick' to efficiently apply a prior to our list of observations. We do this by wrapping filldist() around the Normal(0, 1) call and telling it how many experiments we have (nobs). This is more efficient than looping over a range.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df2b1fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hbb (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model hierachicalBetaBinomial(y, n) = begin\n",
    "    nobs = length(y)\n",
    "    Œº ~ Normal(0,1)\n",
    "    ùúè ~ Normal(0,1)\n",
    "    Œ±z ~ filldist(Normal(0,1), nobs)\n",
    "    Œ± =  Œº .+ Œ±z*ùúè\n",
    "    for i = 1:nobs\n",
    "        y[i] ~ BinomialLogit(n[i], Œ±[i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5722a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
